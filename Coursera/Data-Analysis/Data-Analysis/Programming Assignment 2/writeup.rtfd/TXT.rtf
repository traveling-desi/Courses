{\rtf1\ansi\ansicpg1252\cocoartf1138\cocoasubrtf510
{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;\f1\fnil\fcharset0 Monaco;\f2\fnil\fcharset0 MarkerFelt-Thin;
\f3\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red38\green38\blue38;\red191\green191\blue191;\red0\green28\blue132;
\red174\green119\blue30;\red27\green61\blue19;\red145\green34\blue23;\red191\green191\blue191;}
\margl1440\margr1440\vieww25680\viewh9480\viewkind0
\deftab720
\pard\pardeftab720\sl420

\f0\fs28 \cf2 \
\pard\pardeftab720\sl420

\b\fs40 \cf2 Introduction:\

\b0\fs32 \
This study is to build a function that predicts what activity a subject is performing based on the quantitative measurements from a smartphone. For this analysis we used the dataset complied on a Samsung Galaxy S II phone [1] and downloaded from the UCI dataset website [2]. We describe the study, our predictive model and
\b  include relevant code snippets in gray background
\b0 .\
\

\b\fs40 Methods:
\b0\fs32 \
\
\pard\pardeftab720\sl420

\i \cf2 \ul \ulc2 Data Collection\ulnone \
\pard\pardeftab720\sl420

\i0 \cf2 \
The  data consists of measurements carried out on 
\b 21 unique subjects
\b0 . Different variables were measured using the gyroscope and the accelerometer of the smartphone and further data derviations  (both in time and frequency domain) were carried out on these variables. In all 561 total variables were measure and are listed in the data set. The subjects noted the activity they were performing when the measurements were carried out. These activities were one of ("standing","sitting","laying","walk","walkdown","walkup"). The subject who was performing the activity was noted. In all 7352 observations are recorded. Thus the dataset has 
\b 7352 rows and 563 columns
\b0 .\
In order to build a predictive model we divide the dataset into a train set and a test set.  The test set includes all the data from subjects 27, 28, 29, and 30.  The training set includes all the\'a0data from the remaining subjects  (including subjects 1, 3, 5, and 6 as required by the assignment.) \'a0We were careful to make sure that the 
\b train/test sets do not overlap
\b0 .\'a0\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat3 \clbrdrt\brdrs\brdrw20\brdrcf3 \clbrdrl\brdrs\brdrw20\brdrcf3 \clbrdrb\brdrs\brdrw20\brdrcf3 \clbrdrr\brdrs\brdrw20\brdrcf3 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\tx7280\tx7840\tx8400\tx8960\tx9520\tx10080\tx10640\tx11200\tx11760\tx12320\tx12880\tx13440\tx14000\tx14560\tx15120\tx15680\tx16240\tx16800\tx17360\tx17920\tx18480\tx19040\tx19600\tx20160\tx20720\tx21280\tx21840\tx22400\tx22960\tx23520\tx24080\tx24640\tx25200\tx25760\tx26320\tx26880\tx27440\tx28000\tx28560\tx29120\tx29680\tx30240\tx30800\tx31360\tx31920\tx32480\tx33040\tx33600\tx34160\tx34720\tx35280\tx35840\pardeftab720\li80\fi-80\pardirnatural

\f1\fs28 \cf0 testset_sd\cf4  <- \cf0 sd\cf4 [\cf0 sd\cf4 $\cf0 subject\cf4 %\cf5 in\cf4 %c(\cf6 27\cf4 ,\cf6 28\cf4 ,\cf6 29\cf4 ),]\
\cf0 trainset_sd\cf4  <- \cf0 sd\cf4 [!\cf0 sd\cf4 $\cf0 subject\cf4 %\cf5 in\cf4 %c(\cf6 27\cf4 ,\cf6 28\cf4 ,\cf6 29\cf4 ),]
\fs22 \cell \lastrow\row
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\tx7280\tx7840\tx8400\tx8960\tx9520\tx10080\tx10640\tx11200\tx11760\tx12320\tx12880\tx13440\tx14000\tx14560\tx15120\tx15680\tx16240\tx16800\tx17360\tx17920\tx18480\tx19040\tx19600\tx20160\tx20720\tx21280\tx21840\tx22400\tx22960\tx23520\tx24080\tx24640\tx25200\tx25760\tx26320\tx26880\tx27440\tx28000\tx28560\tx29120\tx29680\tx30240\tx30800\tx31360\tx31920\tx32480\tx33040\tx33600\tx34160\tx34720\tx35280\tx35840\pardeftab720\li80\fi-80\pardirnatural

\f0\fs32 \cf0 The README.txt [2] included with dataset gives an explanation of the variables measured and the dataset creation but a good explanation can also be found here [3]\

\f1 \cf4 \

\f0 \cf2 \
\pard\pardeftab720\sl420

\i \cf2 \ul Exploratory Analysis\
\pard\pardeftab720\sl420

\i0 \cf2 \ulnone \
Some of the measurement columns have duplicated names (yet contain unique information) which result in errors in downstream R commands. Since we did not want to throw out any unique information we decided to uniquify the names of the columns. We did this before we divided them into train/test set. We also changed the column names to a more readable format\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat3 \clbrdrt\brdrs\brdrw20\brdrcf3 \clbrdrl\brdrs\brdrw20\brdrcf3 \clbrdrb\brdrs\brdrw20\brdrcf3 \clbrdrr\brdrs\brdrw20\brdrcf3 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\tx7280\tx7840\tx8400\tx8960\tx9520\tx10080\tx10640\tx11200\tx11760\tx12320\tx12880\tx13440\tx14000\tx14560\tx15120\tx15680\tx16240\tx16800\tx17360\tx17920\tx18480\tx19040\tx19600\tx20160\tx20720\tx21280\tx21840\tx22400\tx22960\tx23520\tx24080\tx24640\tx25200\tx25760\tx26320\tx26880\tx27440\tx28000\tx28560\tx29120\tx29680\tx30240\tx30800\tx31360\tx31920\tx32480\tx33040\tx33600\tx34160\tx34720\tx35280\tx35840\pardeftab720\li80\fi-80\pardirnatural

\f1\fs28 \cf4 names(\cf0 sd\cf4 ) <- gsub(\cf7 "\\\\)"\cf4 ,\cf7 ""\cf4 ,names(\cf0 sd\cf4 ))\
names(\cf0 sd\cf4 ) <- gsub(\cf7 "\\\\("\cf4 ,\cf7 ""\cf4 ,names(\cf0 sd\cf4 ))\
names(\cf0 sd\cf4 ) <- make.names(names(\cf0 sd\cf4 ),\cf0 unique\cf4  =\cf5 TRUE\cf4 )
\f0 \cf2 \cell \lastrow\row
\pard\pardeftab720\sl420

\fs32 \cf2 Finally we removed the subject column from the train and test set since it had no predictive value after the train/test were created.\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat3 \clbrdrt\brdrs\brdrw20\brdrcf3 \clbrdrl\brdrs\brdrw20\brdrcf3 \clbrdrb\brdrs\brdrw20\brdrcf3 \clbrdrr\brdrs\brdrw20\brdrcf3 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\tx7280\tx7840\tx8400\tx8960\tx9520\tx10080\tx10640\tx11200\tx11760\tx12320\tx12880\tx13440\tx14000\tx14560\tx15120\tx15680\tx16240\tx16800\tx17360\tx17920\tx18480\tx19040\tx19600\tx20160\tx20720\tx21280\tx21840\tx22400\tx22960\tx23520\tx24080\tx24640\tx25200\tx25760\tx26320\tx26880\tx27440\tx28000\tx28560\tx29120\tx29680\tx30240\tx30800\tx31360\tx31920\tx32480\tx33040\tx33600\tx34160\tx34720\tx35280\tx35840\pardeftab720\li80\fi-80\pardirnatural

\f1\fs28 \cf0 testset_sd\cf4  <- subset(\cf0 testset_sd\cf4 ,\cf0 select\cf4 =-\cf0 subject\cf4 )\
\cf0 trainset_sd\cf4  <- subset(\cf0 trainset_sd\cf4 ,\cf0 select\cf4 =-\cf0 subject\cf4 )
\f0\fs32 \cf2 \cell \lastrow\row
\pard\pardeftab720\sl420
\cf2 There weren't any missing data/observations. As noted above in Data Collection, we created the train/test sets. We 
\b did not create the validation set, 
\b0 instead using all the remaining data in the
\b  
\b0 train set. This is because the model that we finalize on is capable of doing cross-validation while it is working on the train set. After this data management 
\b we have a train set with 6250 observations on 561 variables and a test set on 1102 observations and 561 variables
\b0 .\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\tx7280\tx7840\tx8400\tx8960\tx9520\tx10080\tx10640\tx11200\tx11760\tx12320\tx12880\tx13440\tx14000\tx14560\tx15120\tx15680\tx16240\tx16800\tx17360\tx17920\tx18480\tx19040\tx19600\tx20160\tx20720\tx21280\tx21840\tx22400\tx22960\tx23520\tx24080\tx24640\tx25200\tx25760\tx26320\tx26880\tx27440\tx28000\tx28560\tx29120\tx29680\tx30240\tx30800\tx31360\tx31920\tx32480\tx33040\tx33600\tx34160\tx34720\tx35280\tx35840\pardeftab720\li80\fi-80\pardirnatural
\cf2 \
\
\
\pard\pardeftab720\sl420

\i \cf2 \ul Statistical Modeling\
\pard\pardeftab720\sl420

\i0 \cf2 \ulnone \
The problem we are working on is a classification/prediction problem and not a linear regression problem. This suggests that the 
\b relevant models to be used for prediction are trees and randomForests
\b0  (in classification mode). This also suggests that lm or glm models are likely to be less useful. We will thus concentrate our efforts trees and randomForests. We will briefly describe, without going into details, another more advanced method(Support Vector Machine).\
\
\pard\pardeftab720\sl420

\b \cf2 Tree
\b0 \
\
The first classification model that we choose to evaluate is a normal tree model using all the variables for classification. It gives us a tree with 8 variables to split on. We then run cross validation on the tree and plot it to find the most relevant top variables. From the cross validation (
\f2 Figure 1
\f0 ) we find that all 8 variables contribute to a reduction of deviation and hence we do not prune the tree. The tree that we get is shown below in 
\f2 Figure1
\f0 \

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat3 \clbrdrt\brdrs\brdrw20\brdrcf3 \clbrdrl\brdrs\brdrw20\brdrcf3 \clbrdrb\brdrs\brdrw20\brdrcf3 \clbrdrr\brdrs\brdrw20\brdrcf3 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\tx7280\tx7840\tx8400\tx8960\tx9520\tx10080\tx10640\tx11200\tx11760\tx12320\tx12880\tx13440\tx14000\tx14560\tx15120\tx15680\tx16240\tx16800\tx17360\tx17920\tx18480\tx19040\tx19600\tx20160\tx20720\tx21280\tx21840\tx22400\tx22960\tx23520\tx24080\tx24640\tx25200\tx25760\tx26320\tx26880\tx27440\tx28000\tx28560\tx29120\tx29680\tx30240\tx30800\tx31360\tx31920\tx32480\tx33040\tx33600\tx34160\tx34720\tx35280\tx35840\pardeftab720\li80\fi-80\pardirnatural

\f1\fs28 \cf0 tree1\cf4  <- tree(as.factor(\cf0 activity\cf4 ) ~ \cf0 .\cf4 , \cf0 trainset_sd\cf4 )\
\cf0 cv_tree \cf4 <- cv.tree(\cf0 tree1\cf4 )
\f0\fs32 \cf2 \cell \lastrow\row
\pard\pardeftab720\sl420
\cf2 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural

\f3\fs24 \cf0 \
{{\NeXTGraphic test.pdf \width10060 \height8480
}¬}\

\f2\fs28 \cf2 Figure 1: The classification tree using all the 561 variables in classification \
and the deviance reduction as function of the size of the tree.
\f0\fs32 \
\
The misclassification error rate of the tree on the training set is 10.21% as shown below:\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat3 \clbrdrt\brdrs\brdrw20\brdrcf3 \clbrdrl\brdrs\brdrw20\brdrcf3 \clbrdrb\brdrs\brdrw20\brdrcf3 \clbrdrr\brdrs\brdrw20\brdrcf3 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\sl216\slmult1

\f1\fs28 \cf0 Number of terminal nodes:  8 \
Residual mean deviance:  0.6382 = 3984 / 6242 \
Misclassification error rate: 0.1021 = 638 / 6250 
\f0\fs32 \cf2 \cell \lastrow\row
\pard\pardeftab720\sl420
\cf2 \
\pard\pardeftab720\sl420

\b \cf2 randomForest[4]
\b0 \
\
Next we try a random forest on all the variables. 
\fs28 \

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat3 \clbrdrt\brdrs\brdrw20\brdrcf3 \clbrdrl\brdrs\brdrw20\brdrcf3 \clbrdrb\brdrs\brdrw20\brdrcf3 \clbrdrr\brdrs\brdrw20\brdrcf3 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\sl420

\f1 \cf2 system.time(forest_sd <- randomForest(as.factor(activity) ~ ., data=trainset_sd, prox=TRUE, ntree=150, importance=T))\
\pard\intbl\itap1\pardeftab720\sl216\slmult1
\cf2   \
      OOB estimate of  error rate: 1.89%\
Confusion matrix:\
         laying sitting standing walk walkdown walkup  class.error\
laying     1183       0        0    0        0      1 0.0008445946\
sitting       0    1052       31    0        0      1 0.0295202952\
standing      0      49     1101    0        0      0 0.0426086957\
walk          0       0        0 1048        7      7 0.0131826742\
walkdown      0       0        0    5      835      8 0.0153301887\
walkup        0       0        0    3        6    913 0.0097613883
\f0 \cell \lastrow\row
\pard\pardeftab720\sl420

\fs32 \cf2 The misclassification error, confusion matrix and OOB error on the train set is also as given above. We use system.time to measure (
\b 0.884 units of time
\b0 ) the time it took to create the randomForest object. The importance variables are plotted in 
\f2 Figure 2
\f0 . We will try to create a random Forest with just a limited number of the most important variables.  We use the amount of time to create a randomForest object and the misclassification error to gauge the efficiency of reducing the # of variables used in creating an object. Once we have a new efficient randomForest with a limited numbers of variables and reasonable misclassification error we will use it to test on the test set.
\fs28 \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural

\f3\fs24 \cf0 {{\NeXTGraphic test1.pdf \width12980 \height8480
}¬}\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural

\f0\fs28 \cf2 \
\pard\pardeftab720\sl420

\f2 \cf2 Figure 2: Importance Variables in the randomForest on 561 Variables.
\f0 \
\
\pard\pardeftab720\sl420

\fs32 \cf2 From the above importance variables we select the most important variables (for all X,Y,Z coordinates) and run a randomForest a second time and create a confusion matrix. Again we use system.time to measure the system runtime (
\b 0.469 units of time
\b0 ). Thus we were able to reduce the # of variables from 561 down to ~ 30 variables and improving the run time by close to 100% (halving the run time). The OOB error increased from 1.89% to 1.92% which is negligible penalty to pay for 2x increase in efficiency.  We thus finalize on a randomForest model using the variables as described below.
\fs28 \

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat8 \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\tx7280\tx7840\tx8400\tx8960\tx9520\tx10080\tx10640\tx11200\tx11760\tx12320\tx12880\tx13440\tx14000\tx14560\tx15120\tx15680\tx16240\tx16800\tx17360\tx17920\tx18480\tx19040\tx19600\tx20160\tx20720\tx21280\tx21840\tx22400\tx22960\tx23520\tx24080\tx24640\tx25200\tx25760\tx26320\tx26880\tx27440\tx28000\tx28560\tx29120\tx29680\tx30240\tx30800\tx31360\tx31920\tx32480\tx33040\tx33600\tx34160\tx34720\tx35280\tx35840\pardeftab720\li80\fi-80\pardirnatural

\f1 \cf4 system.time(\cf0 forest_sd_2\cf4  <- randomForest(as.factor(\cf0 activity\cf4 ) ~ \
\cf0 tGravityAcc.min.X\cf4    + \cf0 tGravityAcc.mean.X\cf4     +  \cf0 tGravityAcc.max.X\cf4    + \cf0 tGravityAcc.energy.X\cf4   + \
\cf0 tGravityAcc.min.Y\cf4    + \cf0 tGravityAcc.mean.Y\cf4     +  \cf0 tGravityAcc.max.Y\cf4    + \cf0 tGravityAcc.energy.Y\cf4   +\
\cf0 tGravityAcc.min.Z\cf4    + \cf0 tGravityAcc.mean.Z\cf4     +  \cf0 tGravityAcc.max.Z  \cf4  + \cf0 tGravityAcc.energy.Z\cf4   +\
\cf0 angleX.gravityMean\cf4   + \cf0 angleY.gravityMean\cf4     +  \cf0 angleZ.gravityMean\cf4   +  \
\cf0 fBodyAccJerk.energy.X\cf4   + \cf0 fBodyAccJerk.energy.Y\cf4   + \cf0 fBodyAccJerk.energy.Z\cf4   + \
\cf0 tBodyAcc.correlation.X.Y\cf4  + \cf0 tBodyAcc.correlation.X.Z\cf4  + \cf0 tBodyAcc.correlation.Y.Z\cf4  +\
\cf0 tGravityAcc.arCoeff.X.1\cf4  + \cf0 tGravityAcc.arCoeff.X.2\cf4  + \cf0 tGravityAcc.arCoeff.X.3\cf4  + \cf0 tGravityAcc.arCoeff.X.4\cf4  +\
\cf0 tGravityAcc.arCoeff.Y.1\cf4  + \cf0 tGravityAcc.arCoeff.Y.2\cf4  + \cf0 tGravityAcc.arCoeff.Y.3\cf4  + \cf0 tGravityAcc.arCoeff.Y.4\cf4  +\
\cf0 tGravityAcc.arCoeff.Z.1\cf4  + \cf0 tGravityAcc.arCoeff.Z.2\cf4  + \cf0 tGravityAcc.arCoeff.Z.3\cf4  + \cf0 tGravityAcc.arCoeff.Z.4\cf4  + \
\cf0 fBodyAcc.bandsEnergy.1.8\cf4 , \cf0 data\cf4 =\cf0 trainset_sd\cf4 , \cf0 prox\cf4 =\cf5 TRUE\cf4 , \cf0 ntree\cf4 =\cf6 150\cf4 , \cf0 importance\cf4 =\cf5 T\cf4 ))\
\
\cf2         OOB estimate of  error rate: 1.92%\
Confusion matrix:\
         laying sitting standing walk walkdown walkup  class.error\
laying     1183       1        0    0        0      0 0.0008445946\
sitting       0    1071       13    0        0      0 0.0119926199\
standing      0      44     1106    0        0      0 0.0382608696\
walk          0       0        0 1032       19     11 0.0282485876\
walkdown      0       0        0    9      828     11 0.0235849057\
walkup        0       0        0    8        4    910 0.0130151844
\f0 \cell \lastrow\row
\pard\pardeftab720\sl420
\cf2 \
\
\pard\pardeftab720\sl420

\i\fs32 \cf2 \ul Reproducibility\
\pard\pardeftab720\sl420

\i0 \cf2 \ulnone \
For the cross validation results and randomForest to be reproducible we need to set the seed for the random number generator. This is essential because these are stochastic (pseudo-random) processes and hence indistinguishable from truly random processes. However they are repeatable if the seed is set before running them. In all our experiments we have set the seed to:
\fs28 \

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat8 \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\sl420

\f1 \cf2 set.seed(123)
\f0 \cell \lastrow\row
\pard\pardeftab720\sl420

\fs32 \cf2 Further it is also important the train and test set be created as we described above to have completely reproducible results. If the train set is has different # of subjects or observations the importance variables may change slightly resulting in a different model.\
\
\pard\pardeftab720\sl420

\b \cf2 Results:\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural

\b0 \cf2 \
Finally after finalizing on the randomForest model we are ready to run the test set on this model and note the misclassification error.
\fs28 \
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clcbpat8 \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural

\f1 \cf2 > table1 <- table(predict(forest_sd_2,newdata=testset_sd,type="class"), testset_sd$activity)\
> table1\
          \
           laying sitting standing walk walkdown walkup\
  laying      223       0        0    0        0      0\
  sitting       0     164       31    0        0      0\
  standing      0      38      193    0        0      0\
  walk          0       0        0  160        1      4\
  walkdown      0       0        0    4      137      2\
  walkup        0       0        0    0        0    145\
> sum(table1[row(table1) != col(table1)])/sum(table1)\
[1] 0.07259528
\f0 \cell \lastrow\row
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 \

\fs32 We do a similar analysis for the randomForest generated from all the variables and the tree generated from all the variables. The results are in the table below:\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 \cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural

\b \cf2 Tree with all Variables\cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 Random Forest with all Variables\cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 Random Forest with ~ 30 important Variable
\b0 s\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural

\b \cf2 Misclassification Error
\b0 \cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 11.7%\cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 4.62%\cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 7.25%\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf8 \clbrdrl\brdrs\brdrw20\brdrcf8 \clbrdrb\brdrs\brdrw20\brdrcf8 \clbrdrr\brdrs\brdrw20\brdrcf8 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural

\b \cf2 Run Time
\b0 \cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 ?\cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 0.884 units of time\cell 
\pard\intbl\itap1\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural
\cf2 0.469 units of time\cell \lastrow\row
\pard\pardeftab720\sl216\slmult1
\cf2 \

\b Confounders: 
\b0 Confounders are variables that are correlated to both the outcome and the covariates. They are hard to detect but may affect analysis. In our dataset it is very likely that the coordinates variable are confounders (i.e if a variable is changing in "X" direction while doing some activity it is very likely that it is changing in "Y" and "Z" direction as well). Confounders are especially important if we are looking for a causal relationship. However since we are working on a classification/prediction problem,  we did not spend time looking and correcting for confounders. However we were particular to include "X", "Y", "Z" measurements for every importance variable in our randomForest to account for confounders.\
\
\pard\pardeftab720\sl420

\b\fs40 \cf2 Conclusions\
\pard\pardeftab720\sl420

\b0\fs32 \cf2 We carried out a study to create a model to predict an activity that a person is engaged in from the measurements of 561 variables from the gyroscope and accelerometer of a smartphone. We finalized on a randomForest model with ~ 30 most important variables (out of a total of 561 possible). The prediction error on the test set was 7.25% but was twice as efficient (comparing run times) than the default randomForest.\
	If the 7.25% prediction rate is not acceptable, we can explore Support Vector Machine(SVM) or Neural Network(NN) based models that will train on all the variables. We need to make sure that the models are not over-trained/over-fitted by performing k-fold cross-validation on the train set.
\b\fs40 \
\
References
\b0\fs32 \
\
[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012\
[2] UCI, Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). Accessed Mar/2/2013\
[3] David T Wilcox, Background on accelerometers, gyros and FFTs
\b , {\field{\*\fldinst{HYPERLINK "https://class.coursera.org/dataanalysis-001/forum/thread?thread_id=2771"}}{\fldrslt 
\b0 https://class.coursera.org/dataanalysis-001/forum/thread?thread_id=2771}}
\b0 . Accessed Mar/6/2013\
[4] Leo Breiman et al, Random Forests {\field{\*\fldinst{HYPERLINK "http://www.stat.berkeley.edu/~breiman/RandomForests/"}}{\fldrslt http://www.stat.berkeley.edu/~breiman/RandomForests/}}. Accessed Mar/8/2013.}